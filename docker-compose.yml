version: '3.8'

# State Placement Cell - Docker Compose Configuration
# Production-ready setup for 60 Polytechnic Colleges in Kerala
#
# IMPORTANT: After starting containers, run the seeding script:
#   docker-compose exec backend node scripts/seedDatabase.js
#
# For automated seeding (CI/CD), set these environment variables:
#   CREATE_SUPER_ADMIN=true
#   SETUP_SECRET_KEY=your-secret-key
#   SUPER_ADMIN_EMAIL=admin@example.com
#   SUPER_ADMIN_PASSWORD=SecurePassword123

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: cpp_postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME:-campus_placement_portal}
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8"
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
      # NOTE: seed-data.sql requires Node.js for password hashing
      # Run seeding manually: docker-compose exec backend node scripts/seedDatabase.js
      - postgres_backups:/backups
    ports:
      - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres} -d ${DB_NAME:-campus_placement_portal}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - cpp_network
    # Resource limits for production (20k+ concurrent users)
    # Adjust based on your server capacity
    deploy:
      resources:
        limits:
          cpus: '4'           # Increased for high-traffic production
          memory: 4G          # Increased for large datasets and connection pools
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
    image: cpp-backend:latest
    container_name: cpp_backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      PORT: 5000
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ${DB_NAME:-campus_placement_portal}
      DB_USER: ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      JWT_SECRET: ${JWT_SECRET:-your_super_secret_jwt_key_change_this}
      JWT_EXPIRE: ${JWT_EXPIRE:-7d}
      JWT_COOKIE_EXPIRE: ${JWT_COOKIE_EXPIRE:-7}
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost}
      CLOUDINARY_CLOUD_NAME: ${CLOUDINARY_CLOUD_NAME}
      CLOUDINARY_API_KEY: ${CLOUDINARY_API_KEY}
      CLOUDINARY_API_SECRET: ${CLOUDINARY_API_SECRET}
      EMAIL_SERVICE: ${EMAIL_SERVICE:-gmail}
      EMAIL_USER: ${EMAIL_USER}
      EMAIL_PASSWORD: ${EMAIL_PASSWORD}
      EMAIL_FROM: ${EMAIL_FROM}
      # Super Admin Setup (for seeding script)
      SETUP_SECRET_KEY: ${SETUP_SECRET_KEY:-}
      CREATE_SUPER_ADMIN: ${CREATE_SUPER_ADMIN:-false}
      SUPER_ADMIN_EMAIL: ${SUPER_ADMIN_EMAIL:-}
      SUPER_ADMIN_PASSWORD: ${SUPER_ADMIN_PASSWORD:-}
    ports:
      - "${BACKEND_PORT:-5000}:5000"
    volumes:
      - backend_uploads:/app/uploads
      - backend_logs:/app/logs
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:5000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - cpp_network
    deploy:
      resources:
        limits:
          cpus: '2'           # Increased for handling 20k concurrent users
          memory: 2G          # Increased for connection handling and in-memory caching
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:5000/api}
    image: cpp-frontend:latest
    container_name: cpp_frontend
    restart: unless-stopped
    depends_on:
      backend:
        condition: service_healthy
    ports:
      - "${FRONTEND_PORT:-80}:80"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - cpp_network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

volumes:
  # Use Docker named volumes for production (better performance and portability)
  # For development with bind mounts, use docker-compose.dev.yml override
  postgres_data:
    driver: local
  postgres_backups:
    driver: local
  backend_uploads:
    driver: local
  backend_logs:
    driver: local

networks:
  cpp_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
